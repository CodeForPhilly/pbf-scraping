name: Fetch Parse & Upload Daily Docket Data


on: [workflow_dispatch]

jobs:
  # Label of the container job
  daily-dockets:
    # Containers must run in Linux based operating systems
    runs-on: ubuntu-latest
    # Docker Hub image that `daily-dockets` executes in
    # This is an image that was manually generated from this project's Dockerfile and put then onto Docker Hub 
    container: rayfallon/pbf-scraping:latest
    steps:
    # Downloads a copy of the code in your repository before running CI tests
    - name: Check out repository code
      uses: actions/checkout@v2
    - name: Install Project Requirements
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
    - name: Fetch and Parse Dockets
      run: |
        chmod -R 777 .
        runuser -l ci-user -c 'python /__w/pbf-scraping/pbf-scraping/analyses/full_dockets/download.py ${{ secrets.AWS_ACCESS_KEY_ID }} ${{ secrets.AWS_SECRET_ACCESS_KEY }}'
    - name: Hey, any dockets in here?
      run: |
        ls -la analyses/full_dockets/tmp/dockets
    - name: Sync Dockets With AWS S3
      uses: jakejarvis/s3-sync-action@v0.5.1
      env:
        AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
        AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        AWS_S3_BUCKET: "pbf-pdf-dockets/data"
        AWS_REGION: "us-east-1"
        SOURCE_DIR: "analyses/full_dockets/tmp/parsed_docket_data/"
