name: Main

on:
  schedule: 
    # Runs every day at 6am EDT (cron in UTC)
    - cron: '0 10 * * *'
  workflow_dispatch:
    inputs:
      date:
        description: 'Date (e.g. 2020-01-31)'     
        required: true
      email:
        description: 'Email to'
  push:
    branches:
      - 'feat-weekly-email'


jobs:
  build:
    # Job name is Greeting
    name: Scrape and store
    # This job runs on Linux
    runs-on: ubuntu-18.04
    defaults:
      run:
        working-directory: 'analyses/ncf_scraping'
    steps:
      - uses: actions/checkout@master
      - name: Set env
        run: |
          if [ -n "${{ github.event.inputs.date }}" ]; then
            echo '::set-env name=scrape_date::'"${{ github.event.inputs.date }}";
          else
            echo '::set-env name=scrape_date::'$(date +%Y-%m-%d -d '1 day ago');
          fi

          if [ "${{ github.event_name }}" == "workflow_dispatch" ]; then
            echo '::set-env name=email::'"${{ github.event.inputs.email }}";
          else
            echo '::set-env name=email::'"${{ env.LISTSERV }}"
          fi

        env:
          LISTSERV: ${{ secrets.LISTSERV }}
      - name: Set day of week
        run: |
          echo '::set-env name=day_of_week::'$(date -d $scrape_date +%A)
      - uses: actions/checkout@v2
      - name: Set up Python
        uses: actions/setup-python@v2
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
        working-directory: './'
      - name: Scrape data
        run: |
          make output/"$scrape_date".csv output/"$scrape_date"_anonymized.csv
      - name: Parse data (daily)
        run: |
          python 1a_parse.py output/"$scrape_date".csv > email_body.txt
      - name: Parse data (weekly)
        if: ${{ env.day_of_week == 'tuesday' }}
        run: |
          start_date=$(date +%Y-%m-%d -d $scrape_date -d '7 days ago')
          python 2_query_between.py "$start_date" "$scrape_date" > weekly.csv
          python 1a_parse.py weekly.csv
        env:
          AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          SCHEMA_NAME: ${{ secrets.SCHEMA_NAME }}
          S3_STAGING_DIR: ${{ secrets.S3_STAGING_DIR }}
          REGION_NAME: ${{ secrets.REGION_NAME }}
      - name: Send mail
        uses: dawidd6/action-send-mail@v2
        if: ${{ env.email && github.ref == 'master' }}
        with:
          server_address: smtp.gmail.com
          server_port: 465
          username: ${{ secrets.MAIL_USERNAME }}
          password: ${{ secrets.MAIL_PASSWORD }}
          subject: Bail Data
          body: file://email_body.txt
          to: ${{ secrets.LISTSERV }}
          from: ${{ secrets.MAIL_USERNAME }}
          attachments: analyses/ncf_scraping/output/${{ env.scrape_date }}.csv
      - name: Delete non-anonymized data
        run: |
          rm output/"$scrape_date".csv
      - name: S3 Sync
        uses: jakejarvis/s3-sync-action@v0.5.1
        env:
          AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          AWS_S3_BUCKET: "pbf-new-criminal-filings"
          AWS_REGION: "us-east-1"
          SOURCE_DIR: "analyses/ncf_scraping/output/"
